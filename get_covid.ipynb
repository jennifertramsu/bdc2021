{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-cc24c0e8-c81f-41a4-9200-081a491c457c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f0278929",
    "execution_start": 1621972370456,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# custom functons\n",
    "from process import *"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = \"coronavirus|sars|covid|endemic|epidemic|pandemic|outbreak|community spread|corona|flattening the curve|social distancing|social distance|quarantine|N95|PPE|stayhome|stayathome|lockdown|wearamask|socialdistancing|ncov|covax|vaccine|symptomatic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new filter\n",
    "# healthorg\n",
    "\n",
    "healthorg_df = filter_data(\"HealthOrg\", strings)\n",
    "healthorg_df = filter_dates(healthorg_df)\n",
    "\n",
    "# export to excel for easier access\n",
    "healthorg_df.to_excel(\"Processed/healthorg.xlsx\")\n",
    "\n",
    "# left news\n",
    "\n",
    "leftnews_df = filter_data(\"News_Outlets/Left\", strings)\n",
    "leftnews_df = filter_dates(leftnews_df)\n",
    "\n",
    "leftnews_df.to_excel(\"Processed/leftnews.xlsx\")\n",
    "\n",
    "# right news\n",
    "\n",
    "rightnews_df = filter_data(\"News_Outlets/Right\", strings)\n",
    "rightnews_df = filter_dates(rightnews_df)\n",
    "\n",
    "rightnews_df.to_excel(\"Processed/rightnews.xlsx\")\n",
    "\n",
    "# right individuals\n",
    "\n",
    "right_df = filter_data(\"Right\", strings)\n",
    "right_df = filter_dates(right_df)\n",
    "\n",
    "right_df.to_excel(\"Processed/rightind.xlsx\")\n",
    "\n",
    "# left individuals\n",
    "\n",
    "left_df = filter_data(\"Left\", strings)\n",
    "left_df = filter_dates(left_df)\n",
    "\n",
    "left_df.to_excel(\"Processed/leftind.xlsx\")\n",
    "\n",
    "# Celebrities\n",
    "\n",
    "celeb_df = filter_data(\"Celebrities\", strings)\n",
    "celeb_df = filter_dates(celeb_df)\n",
    "\n",
    "celeb_df.to_excel(\"Processed/celebrities.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets in higher-node groups removed from fake and real datasets\n",
    "\n",
    "df_names = []\n",
    "files = [healthorg_df, leftnews_df, rightnews_df, right_df, left_df, celeb_df]\n",
    "for df in files:\n",
    "    for line in df[\"username\"].unique():\n",
    "        df_names.append(line)\n",
    "\n",
    "# fake\n",
    "\n",
    "fake = pd.read_excel(\"Processed/fake.xlsx\", index_col=0)\n",
    "fake = fake.drop_duplicates(\"text\")\n",
    "\n",
    "for name in df_names: # removing overlap between groups\n",
    "    fake = fake[fake[\"user_screen_name\"].str.lower().str.contains(name) == False]\n",
    "\n",
    "# exporting new df \n",
    "fake.to_excel(\"Processed/fake.xlsx\")\n",
    "# real\n",
    "\n",
    "real = pd.read_excel(\"Processed/real.xlsx\", index_col=0)\n",
    "real = real.drop_duplicates(\"text\")\n",
    "\n",
    "for name in df_names: # removing overlap between groups\n",
    "    real = real[real[\"user_screen_name\"].str.lower().str.contains(name) == False]\n",
    "\n",
    "real.to_excel(\"Processed/real.xlsx\")"
   ]
  },
  {
   "source": [
    "# Figures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-Day Bins\n",
    "\n",
    "healthorg_df[\"date\"] = pd.to_datetime(healthorg_df[\"date\"])\n",
    "right_df[\"date\"] = pd.to_datetime(right_df[\"date\"])\n",
    "left_df[\"date\"] = pd.to_datetime(left_df[\"date\"])\n",
    "rightnews_df[\"date\"] = pd.to_datetime(rightnews_df[\"date\"])\n",
    "leftnews_df[\"date\"] = pd.to_datetime(leftnews_df[\"date\"])\n",
    "celeb_df[\"date\"] = pd.to_datetime(celeb_df[\"date\"])\n",
    "real_dfs[\"date\"] = pd.to_datetime(real_dfs[\"date\"])\n",
    "fake_dfs[\"date\"] = pd.to_datetime(fake_dfs[\"date\"])\n",
    "\n",
    "health_bins = pd.Series(index=healthorg_df.date, data=np.array(healthorg_df.count)).resample('3D').count()\n",
    "right_bins = pd.Series(index=right_df.date, data=np.array(right_df.count)).resample('3D').count()\n",
    "left_bins = pd.Series(index=left_df.date, data=np.array(left_df.count)).resample('3D').count()\n",
    "rightnews_bins = pd.Series(index=rightnews_df.date, data=np.array(rightnews_df.count)).resample('3D').count()\n",
    "leftnews_bins = pd.Series(index=leftnews_df.date, data=np.array(leftnews_df.count)).resample('3D').count()\n",
    "celeb_bins = pd.Series(index=celeb_df.date, data=np.array(celeb_df.count)).resample('3D').count()\n",
    "real_bins = pd.Series(index=real_dfs.date, data=np.array(real_dfs.count)).resample('3D').count()\n",
    "fake_bins = pd.Series(index=fake_dfs.date, data=np.array(fake_dfs.count)).resample('3D').count()\n",
    "\n",
    "fig, axes = plt.subplots(8, 1, figsize=[30, 20], sharex=True)\n",
    "\n",
    "axes[0].plot(health_bins)\n",
    "axes[0].set_title(\"Health Organizations\")\n",
    "\n",
    "axes[1].plot(right_bins)\n",
    "axes[1].set_title(\"Right-Leaning Individuals\")\n",
    "\n",
    "axes[2].plot(left_bins)\n",
    "axes[2].set_title(\"Left-Leaning Individuals\")\n",
    "\n",
    "axes[3].plot(rightnews_bins)\n",
    "axes[3].set_title(\"Right News Outlets\")\n",
    "\n",
    "axes[4].plot(leftnews_bins)\n",
    "axes[4].set_title(\"Left News Outlets\")\n",
    "\n",
    "axes[5].plot(celeb_bins)\n",
    "axes[5].set_title(\"Celebrity Tweets\")\n",
    "\n",
    "axes[6].plot(fake_bins)\n",
    "axes[6].set_title(\"Fake Tweets\")\n",
    "\n",
    "axes[7].plot(real_bins)\n",
    "axes[7].set_title(\"Real Tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "fig, axes = plt.subplots(8, 1, figsize=[15, 20], sharex=True)\n",
    "\n",
    "axes[0].plot(healthorg_dates.sort_index(), color = '#4E92C5')\n",
    "axes[0].bar(health_bins.index.sort_values(), health_bins, width=3, color = '#A5C8E1')\n",
    "axes[0].set_title(\"Health Organizations\")\n",
    "\n",
    "axes[3].plot(rightnews_dates.sort_index(), color = '#4E92C5')\n",
    "axes[3].bar(rightnews_bins.index.sort_values(), rightnews_bins, width=3, color = '#A5C8E1')\n",
    "axes[3].set_title(\"Right-Wing News Outlets\")\n",
    "\n",
    "axes[4].plot(leftnews_dates.sort_index(), color = '#4E92C5')\n",
    "axes[4].bar(leftnews_bins.index.sort_values(), leftnews_bins, width=3, color = '#A5C8E1')\n",
    "axes[4].set_title(\"Left-Wing News Outlets\")\n",
    "\n",
    "axes[1].plot(right_dates.sort_index(), color = '#4E92C5')\n",
    "axes[1].bar(right_bins.index.sort_values(), right_bins, width=3, color = '#A5C8E1')\n",
    "axes[1].set_title(\"Right-Wing Individuals\")\n",
    "\n",
    "axes[2].plot(left_dates.sort_index(), color = '#4E92C5')\n",
    "axes[2].bar(left_bins.index.sort_values(), left_bins, width=3, color = '#A5C8E1')\n",
    "axes[2].set_title(\"Left-Wing Individuals\")\n",
    "\n",
    "axes[5].plot(celeb_dates.sort_index(), color = '#4E92C5')\n",
    "axes[5].bar(celeb_bins.index.sort_values(), celeb_bins, width=3, color = '#A5C8E1')\n",
    "axes[5].set_title(\"Celebrity Tweets\")\n",
    "\n",
    "axes[6].plot(fake_tweets.sort_index(), color = '#4E92C5')\n",
    "axes[6].bar(fake_bins.index.sort_values(), fake_bins, width=3, color = '#A5C8E1')\n",
    "axes[6].set_title(\"Fake Tweets\")\n",
    "\n",
    "axes[7].plot(real_tweets.sort_index(), color = '#4E92C5')\n",
    "axes[7].bar(real_bins.index.sort_values(), real_bins, width=3, color = '#A5C8E1')\n",
    "axes[7].set_title(\"Real Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-Day Bin\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "healthorg_dates = healthorg_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "right_dates = right_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "left_dates = left_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "rightnews_dates = rightnews_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "leftnews_dates = leftnews_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "celeb_dates = celeb_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "\n",
    "fake_tweets = fake_dfs.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "real_tweets = real_dfs.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(8, 1, figsize=[15, 20], sharex=True)\n",
    "\n",
    "axes[0].plot(healthorg_dates.sort_index())\n",
    "axes[0].plot(healthorg_dates.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[0].set_title(\"Health Organizations\")\n",
    "\n",
    "axes[1].plot(right_dates.sort_index())\n",
    "axes[1].plot(right_dates.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[1].set_title(\"Right-wing Individuals\")\n",
    "\n",
    "axes[2].plot(left_dates.sort_index())\n",
    "axes[2].plot(left_dates.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[2].set_title(\"Left-wing Individuals\")\n",
    "\n",
    "axes[3].plot(rightnews_dates.sort_index())\n",
    "axes[3].plot(rightnews_dates.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[3].set_title(\"Right-wing News Outlets\")\n",
    "\n",
    "axes[4].plot(leftnews_dates.sort_index())\n",
    "axes[4].plot(leftnews_dates.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[4].set_title(\"Left-wing News Outlets\")\n",
    "\n",
    "axes[5].plot(fake_tweets.sort_index())\n",
    "axes[5].plot(fake_tweets.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[5].set_title(\"Fake Tweets\")\n",
    "\n",
    "axes[6].plot(real_tweets.sort_index())\n",
    "axes[6].plot(real_tweets.sort_index().rolling(window=3).mean(), linewidth=5)\n",
    "axes[6].set_title(\"Real Tweets\")\n",
    "\n",
    "axes[7].plot(celeb_dates.sort_index())\n",
    "axes[7].plot(celeb_dates.sort_index().rolling(window=7).mean(), linewidth=5)\n",
    "axes[7].set_title(\"Celebrity Tweets\")\n"
   ]
  },
  {
   "source": [
    "# Archive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-453510b1-44bb-415b-a508-58ddd28cb40d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c9401596",
    "execution_start": 1621972371063,
    "execution_millis": 156,
    "deepnote_cell_type": "code"
   },
   "source": [
    "# credible; makes dictionary of datasets sorted by user (credible), and dataframe of all credible tweets with username as additional column (credible_df) \n",
    "df_path = glob.glob('./HealthOrg/*.csv')\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['username', 'tweet','date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "    # general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "    covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "\n",
    "    df_ls.append(covid)\n",
    "\n",
    "healthorg_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "# fix dates\n",
    "\n",
    "dates = []\n",
    "for date in healthorg_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "healthorg_df[\"date\"] = dates\n",
    "\n",
    "# filter for tweets in first half of 2020\n",
    "\n",
    "healthorg_df = healthorg_df[healthorg_df[\"date\"] <= datetime.date(2020,5,25)]\n",
    "healthorg_df = healthorg_df[healthorg_df[\"date\"] >= datetime.date(2020,3,1)]\n",
    "healthorg_df = healthorg_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "df_names = []\n",
    "for line in healthorg_df[\"username\"].unique():\n",
    "    df_names.append(line)\n",
    "\n",
    "# export to excel for easier access\n",
    "healthorg_df.to_excel(\"Processed/healthorg.xlsx\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left News Outlets\n",
    "df_path = glob.glob('./News_Outlets/Left/*.csv')\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['username', 'tweet', 'date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "    # general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "    covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "    \n",
    "    df_ls.append(covid)\n",
    "\n",
    "leftnews_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "dates = []\n",
    "\n",
    "for date in leftnews_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "leftnews_df[\"date\"] = dates\n",
    "\n",
    "leftnews_df = leftnews_df[leftnews_df[\"date\"] <= datetime.date(2020,5,25)]\n",
    "leftnews_df = leftnews_df[leftnews_df[\"date\"] >= datetime.date(2020,3,1)]\n",
    "\n",
    "leftnews_df = leftnews_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "for line in leftnews_df[\"username\"].drop_duplicates():\n",
    "    df_names.append(line)\n",
    "\n",
    "leftnews_df.to_excel(\"Processed/leftnews.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right News Outlets\n",
    "df_path = glob.glob('./News_Outlets/Right/*.csv')\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['username', 'tweet', 'date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "    # general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "    covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "    \n",
    "    df_ls.append(covid)\n",
    "\n",
    "rightnews_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "dates = []\n",
    "\n",
    "for date in rightnews_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "rightnews_df[\"date\"] = dates\n",
    "\n",
    "rightnews_df = rightnews_df[rightnews_df[\"date\"] <= datetime.date(2020,5,25)]\n",
    "rightnews_df = rightnews_df[rightnews_df[\"date\"] >= datetime.date(2020,3,1)]\n",
    "\n",
    "rightnews_df = rightnews_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "for line in rightnews_df[\"username\"].drop_duplicates():\n",
    "    df_names.append(line)\n",
    "\n",
    "rightnews_df.to_excel(\"Processed/rightnews.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Individuals\n",
    "df_path = glob.glob('./Right/*.csv')\n",
    "trump = pd.read_csv(\"./Right/trump_tweets.csv\") #https://www.kaggle.com/codebreaker619/donald-trump-tweets-dataset\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    if \"trump_tweets\" in path:\n",
    "        continue\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['username', 'tweet','date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "# general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "    covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "    df_ls.append(covid)\n",
    "\n",
    "right_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "dates = []\n",
    "\n",
    "for date in right_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "right_df[\"date\"] = dates\n",
    "\n",
    "right_df = right_df[right_df[\"date\"] <= datetime.date(2020, 5,25)]\n",
    "right_df = right_df[right_df[\"date\"] >= datetime.date(2020,3,1)]\n",
    "right_df = right_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "for line in right_df[\"username\"].drop_duplicates():\n",
    "    df_names.append(line)\n",
    "\n",
    "# rename dataset columns to match others\n",
    "trump[\"username\"] = 'donaldtrump'\n",
    "trump[\"tweet\"] = trump[\"text\"]\n",
    "trump[\"retweets_count\"] = trump[\"retweets\"]\n",
    "trump[\"likes_count\"] = trump[\"favorites\"]\n",
    "trump[\"retweet\"] = trump[\"isRetweet\"]\n",
    "trump.to_csv(\"Right/trump_tweets.csv\")\n",
    "trump = trump[[\"tweet\", \"date\", \"retweets_count\", \"likes_count\", \"retweet\"]]\n",
    "\n",
    "#filter dates\n",
    "trump_dates = trump[\"date\"]\n",
    "trump_dates_corr = []\n",
    "trump_dates_corr = [d[:10] for d in trump_dates]\n",
    "trump_dates_corr = [datetime.datetime.strptime(d, \"%Y-%m-%d\") for d in trump_dates_corr]\n",
    "trump_dates_corr = [datetime.datetime.date(d) for d in trump_dates_corr]\n",
    "trump[\"date\"] = trump_dates_corr\n",
    "\n",
    "trump = trump[trump[\"date\"] >= datetime.date(2020, 3, 1)]\n",
    "trump = trump[trump[\"date\"] <= datetime.date(2020, 5,25)]\n",
    "\n",
    "trump = trump[trump['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "\n",
    "right_df = pd.concat([right_df, trump])\n",
    "\n",
    "for line in right_df[\"username\"].drop_duplicates().dropna():\n",
    "    df_names.append(line)\n",
    "\n",
    "right_df.to_excel(\"Processed/rightind.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump[\"username\"] = 'donaldtrump'\n",
    "trump[\"hashtags\"] = 0\n",
    "trump[\"replies_count\"] = 0\n",
    "trump.to_csv(\"Right/trump_tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Individuals\n",
    "\n",
    "df_path = glob.glob('./Left/*.csv')\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['username', 'tweet','date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "# general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "    covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "\n",
    "    df_ls.append(covid)\n",
    "\n",
    "\n",
    "left_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "dates = []\n",
    "\n",
    "for date in left_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "left_df[\"date\"] = dates\n",
    "left_df = left_df[left_df[\"date\"] <= datetime.date(2020, 5,25)]\n",
    "left_df = left_df[left_df[\"date\"] >= datetime.date(2020, 3, 1)]\n",
    "left_df = left_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "for line in left_df[\"username\"].drop_duplicates():\n",
    "    df_names.append(line)\n",
    "\n",
    "left_df.to_excel(\"Processed/leftind.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celebrities\n",
    "\n",
    "df_path = glob.glob('./Celebrities/*.csv')\n",
    "df_ls = []\n",
    "\n",
    "for path in df_path:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[['username', 'tweet','date', 'replies_count','retweets_count','likes_count','hashtags','retweet']]\n",
    "\n",
    "    # general keywords used for dataset 4: ncov19, ncov2019, covid, rona, stayathome, socialdistancing\n",
    "        covid = df.loc[df['tweet'].str.contains('covid|coronavirus|rona|wearamask|socialdistancing|stayathome|ncov|symptomatic|covax', case=False)]\n",
    "    \n",
    "        df_ls.append(covid)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "celeb_df = pd.concat(df_ls, ignore_index = True)\n",
    "\n",
    "dates = []\n",
    "\n",
    "for date in celeb_df[\"date\"]:\n",
    "    test = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    dates.append(test.date())\n",
    "\n",
    "celeb_df[\"date\"] = dates\n",
    "celeb_df = celeb_df[celeb_df[\"date\"] <= datetime.date(2020, 5,25)]\n",
    "celeb_df = celeb_df[celeb_df[\"date\"] >= datetime.date(2020, 3, 1)]\n",
    "celeb_df = celeb_df.drop_duplicates(\"tweet\")\n",
    "\n",
    "for line in celeb_df[\"username\"].drop_duplicates():\n",
    "    df_names.append(line)\n",
    "\n",
    "celeb_df.to_excel(\"Processed/celebrities.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering CMUID\n",
    "\n",
    "df_cmulabels = pd.read_csv(\"./fake news/CMU_MisCov19_dataset.csv\")[[\"status_id\", \"annotation1\"]]\n",
    "\n",
    "df_cmulabels = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"irrelevant\") == False]\n",
    "df_cmulabels = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"news\") == False]\n",
    "df_cmulabels = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"politics\") == False]\n",
    "df_cmulabels = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"sarcasm\") == False]\n",
    "df_cmulabels = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"commercial\") == False]\n",
    "\n",
    "df1 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"false\") == True]\n",
    "df2 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"fake\") == True]\n",
    "df3 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"conspiracy\") == True]\n",
    "df4 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"panic\") == True]\n",
    "\n",
    "cmu_fake = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "df5 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"true\") == True]\n",
    "df6 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"emergency\") == True]\n",
    "df7 = df_cmulabels[df_cmulabels[\"annotation1\"].str.contains(\"correction\") == True]\n",
    "\n",
    "cmu_real = pd.concat([df5, df6, df7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering FakeNews\n",
    "\n",
    "df_fakenews = pd.read_csv(\"./Covid19_FakeNews_Detection-master/data/Language_CSVs/english.csv\", index_col=0)\n",
    "\n",
    "df_fakenews_f = df_fakenews[df_fakenews[\"label\"] == 0]\n",
    "df_fakenews_r = df_fakenews[df_fakenews[\"label\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake news\n",
    "\n",
    "CMU_fake = pd.read_csv(\"./fake news/cmu_fake_hydrated.csv\", index_col=0)\n",
    "detection_fake = pd.read_csv(\"./Covid19_FakeNews_Detection-master/detection_fake.csv\")\n",
    "#covidFake = pd.read_csv(\"./fake news/covidFakesID_reformatted.csv\", index_col=0)\n",
    "misinformation = pd.read_csv(\"./fake news/Misinformation_hydrated.csv\", index_col=0)\n",
    "fakeTweets = pd.read_csv(\"./Cross-SEAN Dataset/Fake_Tweets.csv\", index_col=0)\n",
    "\n",
    "fake = [CMU_fake, detection_fake, misinformation, fakeTweets]\n",
    "\n",
    "dfs = pd.concat(fake)\n",
    "\n",
    "dfs = dfs[[\"user_name\", \"user_screen_name\", \"text\", \"created_at\", \"retweet_count\", \"favorite_count\", \"hashtags\", \"user_followers_count\", \"user_verified\"]]\n",
    "\n",
    "fake_dfs = dfs\n",
    "\n",
    "# fake_dfs = pd.concat([fake_dfs, dfs])\n",
    "\n",
    "# fix date\n",
    "\n",
    "dates = fake_dfs[\"created_at\"]\n",
    "dates = [date[4:10] + \" \" + date[-4:] for date in dates]\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    test = datetime.datetime.strptime(dates[i], \"%b %d %Y\")\n",
    "    dates[i] = test.date()\n",
    "\n",
    "# reassigned back to df\n",
    "\n",
    "fake_dfs[\"date\"] = dates\n",
    "fake_dfs = fake_dfs.drop(\"created_at\", axis=1)\n",
    "\n",
    "fake_dfs = fake_dfs[fake_dfs[\"date\"] >= datetime.date(2020, 3, 1)]\n",
    "fake_dfs = fake_dfs[fake_dfs[\"date\"] <= datetime.date(2020,5,25)]\n",
    "fake_dfs = fake_dfs.drop_duplicates(\"text\")\n",
    "\n",
    "for name in df_names: # removing overlap between groups\n",
    "    fake_dfs = fake_dfs[fake_dfs[\"user_screen_name\"].str.lower().str.contains(name) == False]\n",
    "\n",
    "fake_dfs.to_excel(\"Processed/fake.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real tweets\n",
    "\n",
    "CMU_real = pd.read_csv(\"./fake news/cmu_real_hydrated.csv\", index_col=0)\n",
    "realTweets = pd.read_csv(\"./Cross-SEAN Dataset/Real_Tweets.csv\", index_col=0)\n",
    "detection_real = pd.read_csv(\"./Covid19_FakeNews_Detection-master/detection_real.csv\")\n",
    "\n",
    "real_dfs = pd.concat([realTweets, CMU_real, detection_real])\n",
    "\n",
    "real_dfs = real_dfs[[\"user_name\", \"user_screen_name\", \"text\", \"created_at\", \"retweet_count\", \"favorite_count\", \"hashtags\", \"user_followers_count\", \"user_verified\"]]\n",
    "\n",
    "# fix date\n",
    "dates = real_dfs[\"created_at\"]\n",
    "dates = [date[4:10] + \" \" + date[-4:] for date in dates]\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    test = datetime.datetime.strptime(dates[i], \"%b %d %Y\")\n",
    "    dates[i] = test.date()   \n",
    "\n",
    "# reassigned back to df\n",
    "real_dfs[\"date\"] = dates\n",
    "real_dfs = real_dfs[real_dfs[\"date\"] >= datetime.date(2020, 3, 1)]\n",
    "real_dfs = real_dfs[real_dfs[\"date\"] <= datetime.date(2020,5,25)]\n",
    "real_dfs = real_dfs.drop(\"created_at\", axis=1)\n",
    "real_dfs = real_dfs.drop_duplicates(\"text\")\n",
    "\n",
    "for name in df_names: # removing overlap between groups\n",
    "    real_dfs = real_dfs[real_dfs[\"user_screen_name\"].str.lower().str.contains(name) == False]\n",
    "\n",
    "real_dfs.to_excel(\"Processed/real.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthorg_dates = healthorg_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "right_dates = right_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "left_dates = left_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "rightnews_dates = rightnews_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "leftnews_dates = leftnews_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "celeb_dates = celeb_df.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "\n",
    "fake_tweets = fake_dfs.sort_values(\"date\", ascending=True)[\"date\"].value_counts()\n",
    "real_tweets = real_dfs.sort_values(\"date\", ascending=True)[\"date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total followers\n",
    "file = pd.read_csv(\"healthorg_followers\", usecols=[0, 1])\n",
    "healthorg_followers = file[\"followers\"].sum()\n",
    "\n",
    "file = pd.read_csv(\"right_followers\", usecols=[0, 1])\n",
    "right_followers = file[\"followers\"].sum()\n",
    "\n",
    "file = pd.read_csv(\"left_followers\", usecols=[0, 1])\n",
    "left_followers = file[\"followers\"].sum()\n",
    "\n",
    "file = pd.read_csv(\"rightnews_followers\", usecols=[0, 1])\n",
    "rightnews_followers = file[\"followers\"].sum()\n",
    "\n",
    "file = pd.read_csv(\"leftnews_followers\", usecols=[0, 1])\n",
    "leftnews_followers = file[\"followers\"].sum()\n",
    "\n",
    "file = pd.read_csv(\"celebrity_followers\", usecols=[0, 1])\n",
    "celeb_followers = file[\"followers\"].sum()\n",
    "\n",
    "fake_followers = fake_dfs[\"user_followers_count\"].drop_duplicates().sum()\n",
    "\n",
    "real_followers = real_dfs[\"user_followers_count\"].drop_duplicates().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet count\n",
    "\n",
    "health_count = healthorg_df[\"tweet\"].count()\n",
    "right_count = right_df[\"tweet\"].count()\n",
    "left_count = left_df[\"tweet\"].count()\n",
    "rightnews_count = rightnews_df[\"tweet\"].count()\n",
    "leftnews_count = leftnews_df[\"tweet\"].count()\n",
    "celeb_count = celeb_df[\"tweet\"].count()\n",
    "\n",
    "fake_count = fake_dfs[\"text\"].count()\n",
    "real_count = real_dfs[\"text\"].count()\n",
    "\n",
    "print(\"HealthOrg Tweets: \\t{}\\nPolitically-Right Leaning Tweets: \\t{}\\nPolitically-Left Leaning Tweets:\\t{}\\nRight News Outlet Tweets: \\t{}\\nLeft News Outlet Tweets: \\t{}\\nFake Tweets:\\t\\t{}\\nReal Tweets:\\t\\t{}\\nCelebrity Tweets:\\t{}\\n\".format(health_count, right_count, left_count, rightnews_count, leftnews_count, fake_count, real_count, celeb_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# followers count\n",
    "\n",
    "print(\"HealthOrg Followers: \\t{}\\nRight Followers: \\t{}\\nLeft Followers:\\t\\t{}\\nRight News Outlet Followers: \\t{}\\nLeft News Outlet Followers: \\t{}\\nFake Followers:\\t\\t{}\\nReal Followers:\\t\\t{}\\nCelebrity Followers:\\t{}\\n\".format(healthorg_followers, right_followers, left_followers, rightnews_followers, leftnews_followers, fake_followers, real_followers, celeb_followers))"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "2e568cc1-9106-404a-b21e-84fb7b0781c3",
  "deepnote_execution_queue": [],
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "interpreter": {
   "hash": "df1d4501566b1753f163333fdb4ef33fd168166ab063e105c1cfc0db7fb36182"
  }
 }
}